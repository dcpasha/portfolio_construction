import pandas as pd
import numpy as np
import scipy.stats 
from scipy.stats import norm


def drawdown(return_series: pd.Series):
    """
    Takes a time series of asset returns.
    Returns a DataFrame with colums:
    for the wealth index, the previos peaks, and
    the percentage drawdown
    """
    wealth_index = 1000*(1+return_series).cumprod()
    previous_peaks = wealth_index.cummax()
    drawdowns = (wealth_index - previous_peaks)/wealth_index
    return pd.DataFrame({
        "Wealth": wealth_index,
        "Previos Peak": previous_peaks,
        "Drawdown": drawdowns
    })

def get_ffme_returns():
    """
    Load the Fama-French Dataset for the returns of the Top and Bottom Deciles 
    by MarketCap
    """
    me_m = pd.read_csv("/Users/iuliia/Desktop/data/Portfolios_Formed_on_ME_monthly_EW.csv",
                      header=0, index_col=0, na_values=-99.99)
    rets = me_m[['Lo 10', 'Hi 10']]
    rets.columns = ['SmallCap', 'LargeCap']
    rets = rets/100
    rets.index = pd.to_datetime(rets.index, format="%Y%m").to_period('M')
    return rets


def get_hfi_returns():
    """
    Load and Format the EHEC Hedge Fund Index
    """
    hfi = pd.read_csv("/Users/pavelpotapov/Coursera/Portfolio/notebooks_and_codem01_v02/data/edhec-hedgefundindices.csv", header=0, index_col=0, parse_dates=True)
    hfi = hfi/100
    hfi.index = hfi.index.to_period('M')
    return hfi

def get_ind_returns():
    """
    Load and Format the Ken French 30 Industry Portfolio Value Weighter Montly Returns.
    """
    # The return of 30 different industry portfolios
    ind = pd.read_csv('/Users/pavelpotapov/Coursera/Portfolio/notebooks_and_codem01_v02/data/ind30_m_vw_rets.csv',
                 header=0, index_col=0, parse_dates=True)/100
    # Converting index to Date
    ind.index = pd.to_datetime(ind.index, format="%Y%m").to_period('M')
    # Get rid of spaces in column names.
    ind.columns = ind.columns.str.strip()
    return ind


def get_ind_size():
    """
    """
    # The return of 30 different industry portfolios
    ind = pd.read_csv('/Users/pavelpotapov/Coursera/Portfolio/notebooks_and_codem01_v02/data/ind30_m_size.csv',
                 header=0, index_col=0, parse_dates=True)
    # Converting index to Date
    ind.index = pd.to_datetime(ind.index, format="%Y%m").to_period('M')
    # Get rid of spaces in column names.
    ind.columns = ind.columns.str.strip()
    return ind

def get_ind_nfirms():
    """
    """
    # The return of 30 different industry portfolios
    ind = pd.read_csv('/Users/pavelpotapov/Coursera/Portfolio/notebooks_and_codem01_v02/data/ind30_m_nfirms.csv',
                 header=0, index_col=0, parse_dates=True)
    # Converting index to Date
    ind.index = pd.to_datetime(ind.index, format="%Y%m").to_period('M')
    # Get rid of spaces in column names.
    ind.columns = ind.columns.str.strip()
    return ind


def semideviation(r):
    """
    Returns the semideviation aka negative semideviation of r
    r must be a Series of a DataFrame
    """
    is_negative = r < 0
    return r[is_negative].std(ddof=0)


def skewness(r):
    """
    Alternative to scipy.stats.skew()
    Computes the skewness of the supplied Series or DataFrame
    Returns a float or a Series
    """
    demeaned_r = r - r.mean()
    # use the population standard deviation, so set dof=0
    sigma_r = r.std(ddof=0)
    exp = (demeaned_r**3).mean()
    return exp/sigma_r**3


def kurtosis(r):
    """
    Alternative to scipy.stats.kurtosis()
    Computes the kurtosis of the supplied Series or DataFrame
    Returns a float or a Series
    """
    demeaned_r = r - r.mean()
    # use the population standard deviation, so set dof=0
    sigma_r = r.std(ddof=0)
    exp = (demeaned_r**4).mean()
    return exp/sigma_r**4


def is_normal(r, level=0.01):
    """
    Applies the Jarque-Bera test to determine if a Series is normal or not. 
    Test is applied at the 1% level by default.
    Returns True if the hypothesis of normality is accepted, False otherwise.
    .jarque_bera returns a tuple
    """ 
    statistic, p_value = scipy.stats.jarque_bera(r)
    return p_value > level


def var_historic(r, level=5):
    """
    Returns the historic Value at Risk at a specified level
    i.e. returns the number such that "level" percent of the returns
    fall below that number, and the (100-level) percent are above
    """
    if isinstance(r, pd.DataFrame):
        return r.aggregate(var_historic, level=level)
    elif isinstance(r, pd.Series):
        return -np.percentile(r, level)
    else:
        raise TypeError("Expected r to be a Series or DataFrame") 
        


def var_gaussianORG(r, level=5, modified=False):
    """
    Returns the Parametric Gauusian VaR of a Series or DataFrame
    If "modified" is True, then the modified VaR is returned,
    using the Cornish-Fisher modification
    
    VaR is used to evaluate risk.
    It is usually measured at 95%, 99% and 99.9%.
    At level = 5, it means that there is a 5% chance to lose VAR% or more
    on any given day.
    """
    # Compute the Z score assuming it was Gaussian
    # Z-score tells us how far it is from the mean.
    z = norm.ppf(level/100)
    if modified:
        # modify the Z score based on observed skewness and kurtosis
        s = skewness(r)
        k = kurtosis(r)
        z = (z +
                (z**2 - 1)*s/6 +
                (z**3 -3*z)*(k-3)/24 -
                (2*z**3 - 5*z)*(s**2)/36
            )        

    return -(r.mean() + z*r.std(ddof=0))


def var_gaussian(r, level=5, modified=False):
    """
    Returns the Parametric Gauusian VaR of a Series or DataFrame
    If "modified" is True, then the modified VaR is returned,
    using the Cornish-Fisher modification
    """
    # compute the Z score assuming it was Gaussian
    z = norm.ppf(level/100)
    if modified:
        # modify the Z score based on observed skewness and kurtosis
        s = skewness(r)
        k = kurtosis(r)
        z = (z +
                (z**2 - 1)*s/6 +
                (z**3 -3*z)*(k-3)/24 -
                (2*z**3 - 5*z)*(s**2)/36
            )
    return -(r.mean() + z*r.std(ddof=0))


def cvar_historic(r, level=5):
    """
    Computes the Conditional VaR of Series or DataFrame
    
    CVaR is used to evaluate risk.
    It is usually measured at 95%, 99% and 99.9%.
    At level = 5, it means that in the worst 5% of returns, 
    your AVERAGE loss will be %CVaR.
    """
    if isinstance(r, pd.Series):
        is_beyond = r <= -var_historic(r, level=level)
        return -r[is_beyond].mean()
    elif isinstance(r, pd.DataFrame):
        return r.aggregate(cvar_historic, level=level)
    else:
        raise TypeError("Expected r to be Series or DataFrame")

        

def annualize_rets(r, periods_per_year):
    """
    Annualizes a set of returns
    """
    compounded_growth = (1+r).prod()
    n_periods = r.shape[0]
    return compounded_growth**(periods_per_year/n_periods)-1

def annualize_vol(r, periods_per_year):
    """
    Annualizes the vol of a set of returns
    We should infer the periods per year
    but that is currently left as an exercise
    to the reader :-)
    """
    return r.std()*(periods_per_year**0.5)

def sharpe_ratio(r, riskfree_rate, periods_per_year):
    """
    Computes the annualized sharpe ratio of a set of returns
    """
    # Convert the annual risk-free rate to per period
    rf_per_period = (1+riskfree_rate)**(1/periods_per_year)-1
    excess_ret = r - rf_per_period
    ann_ex_ret = annualize_rets(excess_ret, periods_per_year)
    ann_vol = annualize_vol(r, periods_per_year)
    return ann_ex_ret/ann_vol


def portfolio_return(weights, returns):
    """
    Weights -> Returns
    """
    # We perform a matrix multiplication.
    return weights.T @ returns


def portfolio_vol(weights, covmat):
    """
    Computes the vol of a portfolio from a covariance matrix and constituent weights
    weights are a numpy array or N x 1 maxtrix and covmat is an N x N matrix
    """
    return (weights.T @ covmat @ weights)**0.5


def plot_ef2(n_points, er, cov):
    """
    Plots the 2-asset efficient frontier
    """
    if er.shape[0] != 2 or er.shape[0] != 2:
        raise ValueError("plot_ef2 can only plot 2-asset frontiers")
    weights = [np.array([w, 1-w]) for w in np.linspace(0, 1, n_points)]
    rets = [portfolio_return(w, er) for w in weights]
    vols = [portfolio_vol(w, cov) for w in weights]
    ef = pd.DataFrame({
        "Returns": rets, 
        "Volatility": vols
    })
    return ef.plot.line(x="Volatility", y="Returns", style=".-")




from scipy.optimize import minimize

def minimize_vol(target_return, er, cov):
    """
    Returns the optimal weights that achieve the target return
    given a set of expected returns and a covariance matrix.
    
    The optimizer needs: an objective function, constraints and an initial guess.
    """
    n = er.shape[0] # To figure out how many returns we have.
    init_guess = np.repeat(1/n, n) # We use equal weights as Initial guess for our weights.
    bounds = ((0.0, 1.0),) * n # Bounds for every asset weights. An N-tuple of 2-tuples!
    # We create this tuple for every asset that we have.
    
    # Construct the Constraints
    weights_sum_to_1 = {'type': 'eq',
                        'fun': lambda weights: np.sum(weights) - 1 # it should be equal to 0.
    }
    return_is_target = {'type': 'eq', # type of constraint is eq (equality)
                        'args': (er,),
                        'fun': lambda weights, er: target_return - portfolio_return(weights,er) # it should be equal to 0.
    }
    
    # Calling the optimizer. We want to minimize the volatility subject to the return_target
    # Optimizer will generate a set of weights.
    results = minimize(portfolio_vol, init_guess,
                       args=(cov,), method='SLSQP', # Sequential Least Squares Programming 
                       options={'disp': False},
                       constraints=(weights_sum_to_1,return_is_target),
                       bounds=bounds)
    return results.x

def optimal_weights(n_points, er, cov):
    """
    Generates a list of weights to run the optimizer on to minimize the volatility.

    """
    target_rs = np.linspace(er.min(), er.max(), n_points)
    # For each target_return, we get a weight.
    weights = [minimize_vol(target_return, er, cov) for target_return in target_rs]
    return weights
    
    
def msr(riskfree_rate, er, cov):
    """
    Returns the weights of the portfolio that gives you the Maximum Sharpe Ratio
    given the riskfree rate and expected returns and a covariance matrix.
    
    MSR - Maximum Sharpe Ratio
    """
    n = er.shape[0]
    init_guess = np.repeat(1/n, n)
    bounds = ((0.0, 1.0),) * n # an N-tuple of 2-tuples!

    # Construct the constraints
    weights_sum_to_1 = {'type': 'eq',
                        'fun': lambda weights: np.sum(weights) - 1
    }
    
    # F-n that minimizer tries to minimize.
    def neg_sharpe(weights, riskfree_rate, er, cov):
        """
        Returns the negative of the sharpe ratio
        of the given portfolio
        """
        r = portfolio_return(weights, er)
        vol = portfolio_vol(weights, cov)
        return -(r - riskfree_rate)/vol
    
    weights = minimize(neg_sharpe, init_guess,
                       args=(riskfree_rate, er, cov), method='SLSQP',
                       options={'disp': False},
                       constraints=(weights_sum_to_1),
                       bounds=bounds)
    return weights.x    
    
    
def gmv(cov):
    """
    Returns the weights of the Global Minimum Vol Portfolio 
    given the covariance matrix
    """
    n = cov.shape[0] # To find how many assets
    return msr(0, np.repeat(1, n), cov) # we pass expected returns as 1 because we assume that they are all the same.
    
def plot_ef(n_points, er, cov, style='.-', legend=False, riskfree_rate=0, show_cml=False, show_ew = False, show_gmv = False):
    """
    Plots the multi-asset efficient frontier
    """
    # Gives a sequence of weights
    weights = optimal_weights(n_points, er, cov)
    
    # Find a Return and Volatility for each weight.
    rets = [portfolio_return(w, er) for w in weights]
    vols = [portfolio_vol(w, cov) for w in weights]
    ef = pd.DataFrame({
        "Returns": rets, 
        "Volatility": vols
    })
    ax = ef.plot.line(x="Volatility", y="Returns", style=style, legend=legend)
    if show_ew:
        n = er.shape[0] # To find the number of assets
        w_ew = np.repeat(1/n, n)
        r_ew = portfolio_return(w_ew, er)
        vol_ew = portfolio_vol(w_ew, cov)
        # Display EW
        ax.plot([vol_ew], [r_ew], color="goldenrod", marker="o", markersize=10)
    
    if show_gmv:
        w_gmv = gmv(cov) # Generate weights
        print("w_gmv are " + str(w_gmv)) # for Quiz
        r_gmv = portfolio_return(w_gmv, er)
        vol_gmv = portfolio_vol(w_gmv, cov)
        # Display EW
        ax.plot([vol_gmv], [r_gmv], color="midnightblue", marker="o", markersize=10)
    
    
    if show_cml:
        ax.set_xlim(left = 0)
        # get MSR
        w_msr = msr(riskfree_rate, er, cov)
        r_msr = portfolio_return(w_msr, er)
        vol_msr = portfolio_vol(w_msr, cov)
        # add CML
        cml_x = [0, vol_msr]
        cml_y = [riskfree_rate, r_msr]
        ax.plot(cml_x, cml_y, color='green', marker='o', linestyle='dashed', linewidth=2, markersize=12)
    return ax
